{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8701087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import *\n",
    "import importlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions import Distribution, Dirichlet as TorchDirichlet\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "from torch.distributions import Bernoulli\n",
    "from plotting import make_vae_plots\n",
    "import plotting\n",
    "importlib.reload(plotting)\n",
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138f596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go one directory up (from GMVAE to CCVAE) and then into cc\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'cc')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5806c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class LatentType(Enum):\n",
    "    GAUSSIAN = 1\n",
    "    DIRICHLET = 2\n",
    "    CONTINUOUS_CATEGORICAL = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e601961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the images into a vector\n",
    "flatten = lambda x: ToTensor()(x).view(28**2)\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True,  transform=ToTensor(), download=True)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=ToTensor())\n",
    "\n",
    "# The digit classes to use\n",
    "classes = [3, 7]\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9959a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:66: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "c:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:71: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "eval_batch_size = 100\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.train_labels))\n",
    "test_loader  = DataLoader(dset_test, batch_size=eval_batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.test_labels))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "def reduce(x: Tensor) -> Tensor:\n",
    "    \"\"\"Reduce only if tensor has more than one dimension.\"\"\"\n",
    "    return x if x.ndim == 1 else x.view(x.size(0), -1).sum(dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3964d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(z | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, I)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma: Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu`: {mu.shape} and `log_sigma`: {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.log_sigma = log_sigma\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"ε ~ N(0, I)\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"Sample z ~ N(z | mu, sigma) (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"Sample z ~ N(z | mu, sigma) (with the reparameterization trick)\"\"\"\n",
    "        eps = self.sample_epsilon()\n",
    "        return self.mu + self.sigma * eps\n",
    "    \n",
    "    def log_prob(self, z: Tensor) -> Tensor:\n",
    "        log_p = -0.5 * (((z - self.mu) / self.sigma) ** 2 + 2 * self.log_sigma + math.log(2 * math.pi))\n",
    "        if log_p.ndim > 1:\n",
    "            log_p = log_p.sum(dim=-1)\n",
    "        return log_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c5abb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReparameterizedDirichlet(Distribution):\n",
    "    \"\"\"\n",
    "    A reparameterized Dirichlet distribution `Dir(z | alpha)` compatible with the\n",
    "    reparameterization trick (via PyTorch's rsample on Gamma variables).\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha: Tensor):\n",
    "        # alpha can be [batch_size, latent_dim] or [latent_dim]\n",
    "        assert (alpha > 0).all(), \"All concentration parameters (alpha) must be positive\"\n",
    "        self.alpha = alpha\n",
    "        self._dist = TorchDirichlet(alpha)\n",
    "\n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"Sample z ~ Dir(alpha) (without gradients).\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self._dist.sample()\n",
    "\n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"Sample z ~ Dir(alpha) (with gradients via reparameterization).\"\"\"\n",
    "        return self._dist.rsample()\n",
    "\n",
    "    def log_prob(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"Compute log p(z | alpha).\"\"\"\n",
    "        return self._dist.log_prob(z)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------OLD IMPLEMENTATION------------------------\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.distributions import Distribution\n",
    "# class ReparameterizedContinuousCategorical(Distribution):\n",
    "#     \"\"\"\n",
    "#     A reparameterized Continuous Categorical (Gumbel-Softmax) distribution.\n",
    "#     Samples from a relaxed categorical using the Gumbel-Softmax trick.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, logits: torch.Tensor, temperature: float = 1.0):\n",
    "#         super().__init__()\n",
    "#         self.logits = logits\n",
    "#         self.temperature = temperature\n",
    "\n",
    "#     def sample(self) -> torch.Tensor:\n",
    "#         \"\"\"Sample without gradients.\"\"\"\n",
    "#         with torch.no_grad():\n",
    "#             return F.gumbel_softmax(self.logits, tau=self.temperature, hard=False, dim=-1)\n",
    "\n",
    "#     def rsample(self) -> torch.Tensor:\n",
    "#         \"\"\"Reparameterized sample using the Gumbel-Softmax trick.\"\"\"\n",
    "#         return F.gumbel_softmax(self.logits, tau=self.temperature, hard=False, dim=-1)\n",
    "\n",
    "#     def log_prob(self, z: torch.Tensor) -> torch.Tensor:\n",
    "#         \"\"\"Compute approximate log-probability under the relaxed categorical.\"\"\"\n",
    "#         # This is not an exact density but a differentiable approximation\n",
    "#         log_q = torch.sum(z * F.log_softmax(self.logits, dim=-1), dim=-1)\n",
    "#         return log_q\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Distribution\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cc_torch import sample_cc_ordered_torch, cc_log_prob_torch\n",
    "\n",
    "class ReparameterizedContinuousCategorical(Distribution):\n",
    "    \"\"\"\n",
    "    Continuous Categorical (CC) distribution.\n",
    "    Sampling uses the differentiable ordered rejection sampler (Algorithm 2).\n",
    "    Log-probability uses the cc_log_prob function from cc_funcs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.logits = logits\n",
    "\n",
    "    def rsample(self, n_samples=1):\n",
    "        \"\"\"\n",
    "        Differentiable reparameterized sample using the ordered rejection sampler.\n",
    "        \"\"\"\n",
    "        lam = torch.softmax(self.logits, dim=-1)\n",
    "        lam_batch = lam.repeat(n_samples, 1)\n",
    "        samples = sample_cc_ordered_torch(lam_batch)\n",
    "        return samples\n",
    "    \n",
    "    def sample(self, n_samples=1):\n",
    "        \"\"\"\n",
    "        Non-differentiable sample (detached from graph).\n",
    "        \"\"\"\n",
    "        return self.rsample(n_samples).detach()\n",
    "\n",
    "    def log_prob(self, z: torch.Tensor):\n",
    "        lam = torch.softmax(self.logits, dim=-1)\n",
    "        eta = torch.log(lam[:, :-1]) - torch.log(lam[:, -1].unsqueeze(-1))\n",
    "        return cc_log_prob_torch(z, eta)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3871e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta: float = 1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, model: nn.Module, x: Tensor):\n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # unpack outputs\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        log_px = reduce(px.log_prob(x))\n",
    "        log_pz = reduce(pz.log_prob(z))\n",
    "        log_qz = reduce(qz.log_prob(z))\n",
    "        \n",
    "        # compute the KL divergence term\n",
    "        kl = log_qz - log_pz\n",
    "        \n",
    "        # ELBO: log p(x|z) - KL(q||p)\n",
    "        elbo = log_px - kl\n",
    "        \n",
    "        # β-ELBO: log p(x|z) - β * KL(q||p)\n",
    "        beta_elbo = log_px - self.beta * kl\n",
    "        \n",
    "        # loss = -E_q[Lβ]\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # diagnostics for monitoring\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px': log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, input_shape: torch.Size, latent_features: int, latent_type: LatentType, tau_start:float = 2.0) -> None:\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        assert latent_type in [LatentType.GAUSSIAN, LatentType.DIRICHLET, LatentType.CONTINUOUS_CATEGORICAL], \\\n",
    "            \"latent_type must be 'gaussian', 'dirichlet', or 'continuous_categorical'\"\n",
    "\n",
    "\n",
    "        self.latent_type = latent_type\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "\n",
    "        # temperature for Gumbel–Softmax\n",
    "        self.tau = tau_start\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2), \n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(out_features=2 * latent_features if latent_type == LatentType.GAUSSIAN else latent_features)\n",
    "        )\n",
    "\n",
    "        self.fc_dec = nn.Linear(latent_features, 32 * 28 * 28)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=1, padding=2),\n",
    "        )  \n",
    "        \n",
    "        if self.latent_type == LatentType.GAUSSIAN:\n",
    "            self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2 * latent_features])))\n",
    "        elif self.latent_type == LatentType.DIRICHLET:\n",
    "            self.register_buffer('alpha_prior', torch.ones(torch.Size([1, latent_features])))\n",
    "        else:  # continuous categorical\n",
    "            self.register_buffer('logits_prior', torch.zeros(torch.Size([1, latent_features])))\n",
    "\n",
    "    def posterior(self, x: torch.Tensor):\n",
    "        h_x = self.encoder(x)\n",
    "        if self.latent_type == LatentType.GAUSSIAN:\n",
    "            mu, log_sigma = h_x.chunk(2, dim=-1)\n",
    "            return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        elif self.latent_type == LatentType.DIRICHLET:\n",
    "            alpha = F.softplus(h_x) + 1e-4\n",
    "            return ReparameterizedDirichlet(alpha)\n",
    "        else:  # continuous categorical\n",
    "            return ReparameterizedContinuousCategorical(h_x)\n",
    "\n",
    "    def prior(self, batch_size: int = 1):\n",
    "        if self.latent_type == LatentType.GAUSSIAN:\n",
    "            prior_params = self.prior_params.expand(batch_size, -1)\n",
    "            mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "            return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        elif self.latent_type == LatentType.DIRICHLET:\n",
    "            alpha = self.alpha_prior.expand(batch_size, -1)\n",
    "            return ReparameterizedDirichlet(alpha)\n",
    "        else:  # continuous categorical\n",
    "            logits = self.logits_prior.expand(batch_size, -1)\n",
    "            return ReparameterizedContinuousCategorical(logits)\n",
    "        \n",
    "\n",
    "    def observation_model(self, z: torch.Tensor) -> Distribution:\n",
    "        h = self.fc_dec(z)                       # (B, 32*28*28)\n",
    "        h = h.view(-1, 32, 28, 28)               # reshape to feature map\n",
    "        px_logits = self.decoder(h)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits, validate_args=False)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        # encode\n",
    "        qz = self.posterior(x)\n",
    "\n",
    "        # prior\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "\n",
    "\n",
    "        z = qz.rsample()\n",
    "\n",
    "        # decode\n",
    "        px = self.observation_model(z)\n",
    "\n",
    "        return {\"px\": px, \"pz\": pz, \"qz\": qz, \"z\": z}\n",
    "    \n",
    "    def sample_from_prior(self, batch_size: int = 100):\n",
    "        \"\"\"Sample z ~ p(z) and return p(x|z).\"\"\"\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "\n",
    "        # sample latent variable\n",
    "        z = pz.rsample() if hasattr(pz, \"rsample\") else pz.sample()\n",
    "\n",
    "        # decode\n",
    "        px = self.observation_model(z)\n",
    "\n",
    "        return {\"px\": px, \"pz\": pz, \"z\": z}\n",
    "\n",
    "    def sample_from_posterior(self, x: torch.Tensor):\n",
    "        \"\"\"Sample z ~ q(z|x) and return p(x|z).\"\"\"\n",
    "\n",
    "        # encode\n",
    "        qz = self.posterior(x)\n",
    "\n",
    "        # sample latent variable\n",
    "        z = qz.rsample() if hasattr(qz, \"rsample\") else qz.sample()\n",
    "\n",
    "        # decode\n",
    "        px = self.observation_model(z)\n",
    "\n",
    "        return {\"px\": px, \"qz\": qz, \"z\": z}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59369445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\distributions\\distribution.py:56: UserWarning: <class '__main__.ReparameterizedContinuousCategorical'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 2\n",
    "vae = VariationalAutoencoder(images[0].shape, latent_features, latent_type = LatentType.CONTINUOUS_CATEGORICAL)\n",
    "\n",
    "print(images[0].shape)\n",
    "\n",
    "out = vae(torch.randn(1, 1, 28, 28))\n",
    "print(out['px'].sample().shape)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 1\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb9031",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 39\u001b[0m     loss, diagnostics, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mvi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     42\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m, in \u001b[0;36mVariationalInference.forward\u001b[1;34m(self, model, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: nn\u001b[38;5;241m.\u001b[39mModule, x: Tensor):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# forward pass through the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# unpack outputs\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     px, pz, qz, z \u001b[38;5;241m=\u001b[39m [outputs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cahar\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 81\u001b[0m, in \u001b[0;36mVariationalAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# prior\u001b[39;00m\n\u001b[0;32m     78\u001b[0m pz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior(batch_size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 81\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mqz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# decode\u001b[39;00m\n\u001b[0;32m     84\u001b[0m px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_model(z)\n",
      "Cell \u001b[1;32mIn[21], line 26\u001b[0m, in \u001b[0;36mReparameterizedContinuousCategorical.rsample\u001b[1;34m(self, n_samples)\u001b[0m\n\u001b[0;32m     24\u001b[0m lam \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m lam_batch \u001b[38;5;241m=\u001b[39m lam\u001b[38;5;241m.\u001b[39mrepeat(n_samples, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43msample_cc_ordered_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlam_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "File \u001b[1;32mc:\\Users\\cahar\\Documents\\GitHub\\CCVAE\\cc\\cc_samplers_torch.py:60\u001b[0m, in \u001b[0;36msample_cc_ordered_torch\u001b[1;34m(lam_batch)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "from plotting import make_vae_plots\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "vae = vae.to(device)\n",
    "\n",
    "# annealing parameters\n",
    "tau_min = 0.5\n",
    "anneal_rate = 0.0003\n",
    "kl_warmup_epochs = 20  # number of epochs to reach full β\n",
    "max_beta = 0.3\n",
    "\n",
    "\n",
    "while epoch < num_epochs:\n",
    "    epoch += 1\n",
    "    training_epoch_data = defaultdict(list)\n",
    "    vae.train()\n",
    "\n",
    "    # KL warmup: gradually increase β\n",
    "    vi.beta = min(max_beta, epoch / kl_warmup_epochs)\n",
    "\n",
    "    # temperature annealing (only for continuous categorical)\n",
    "    if vae.latent_type == \"continuous_categorical\":\n",
    "        vae.tau = max(vae.tau * np.exp(-anneal_rate * epoch), tau_min)\n",
    "\n",
    "    #print(f\"Epoch {epoch}: beta = {vi.beta:.4f}\", end=\"\")\n",
    "    # if vae.latent_type == \"continuous_categorical\":\n",
    "    #     print(f\", tau = {vae.tau:.4f}\")\n",
    "    # else:\n",
    "    #     print()\n",
    "\n",
    "    # training loop\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for k, v in diagnostics.items():\n",
    "            training_epoch_data[k] += [v.mean().item()]\n",
    "\n",
    "    for k, v in training_epoch_data.items():\n",
    "        training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = x.to(device)\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        for k, v in diagnostics.items():\n",
    "            validation_data[k] += [v.mean().item()]\n",
    "\n",
    "    # visualize\n",
    "    make_vae_plots(vae, x, y, outputs, training_data, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import latent_morphing\n",
    "latent_morphing(vae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
